{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import builtins as __builtin__\n",
    "def print(*args, **kwargs):\n",
    "    return __builtin__.print(*args, **{**kwargs, 'flush':True })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sFVer5bcYzV8"
   },
   "source": [
    "# Paralelismo e concorrência em Python\n",
    "### O que ele faz? Ele faz coisas? Vamos descobrir!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0 - Um problema de interpretação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2U8O-VZihdy"
   },
   "source": [
    "### Global Interpreter Lock\n",
    "\n",
    "[Fonte diss'aqui tudo sobre o GIL](https://realpython.com/python-gil/)\n",
    "\n",
    "1. O GIL é um Lock que controla o interpretador do Python.\n",
    "2. Ele só permite 1 thread usar o interpretador por vez.\n",
    "3. Ele foi criado pra resolver problemas de contagem de referência de variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XKkUnFVwbBct",
    "outputId": "44bcf8d4-bc71-4301-bdee-de7bf183bb9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "foo = [] \n",
    "print(sys.getrefcount(foo))\n",
    "foo.append(5)\n",
    "print(sys.getrefcount(foo))\n",
    "del foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "TLXMtqO3Z8gw",
    "outputId": "ae7e72aa-0569-4886-ecc8-a750d07b234d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "alice = 8\n",
    "print(sys.getrefcount(alice))\n",
    "del alice\n",
    "alice = 4846848648468\n",
    "print(sys.getrefcount(alice))\n",
    "del alice\n",
    "alice = {}\n",
    "print(sys.getrefcount(alice))\n",
    "del alice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ctpnvjX1jJVN",
    "outputId": "264e3558-1f96-44b1-9b6b-5e44fc7d1ba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "burro = 'já chegou chureque'\n",
    "print(sys.getrefcount(burro))\n",
    "print(sys.getrefcount(burro))\n",
    "print(sys.getrefcount(burro))\n",
    "print(sys.getrefcount(burro))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "lEhzsdXtitaR",
    "outputId": "de0a8bb4-4413-41fd-8a33-cdbfc801b109"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "aurelio = dict()\n",
    "print(sys.getrefcount(aurelio))\n",
    "aurelio['ornitorrinco'] = 'é um vegetal'\n",
    "print(sys.getrefcount(aurelio))\n",
    "print(sys.getrefcount(aurelio['ornitorrinco']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oHG8zkzlaGgq",
    "outputId": "8c0eaad8-49ad-498d-83ee-f4c602b8c274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "bar = []\n",
    "print(sys.getrefcount(bar))\n",
    "bar = {}\n",
    "print(sys.getrefcount(bar))\n",
    "del bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8_gSYPm9ghug",
    "outputId": "94156297-7049-4cbb-e683-96aa55131113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "uno = []\n",
    "dos = uno\n",
    "tres = dos\n",
    "cuatro = tres\n",
    "print(sys.getrefcount(cuatro))\n",
    "print(sys.getrefcount(uno))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "leRk4yDhhel5"
   },
   "source": [
    "4. Isso não significa que as thread não sejam reais. Só que elas ficam com a execução pausada caso elas precisem do interpretador.\n",
    "\n",
    "### Quando usar multithreading no python então?\n",
    "#### *Quando as tarefas são I/O bounded ou não precisam reinterpretar código.*\n",
    "\n",
    "Da documentação:  \n",
    "\"*However, threading is still an appropriate model if you want to run multiple I/O-bound tasks simultaneously.*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Act 1: Concurrency\n",
    "Requirements:\n",
    "- python >= 3.3\n",
    "\n",
    "1. A biblioteca de concorrência de python implementa um event loop single threaded com async/await"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "ba\n",
      "ca\n",
      "xi\n",
      "!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-de23d30b153c>:7: DeprecationWarning: \"@coroutine\" decorator is deprecated since Python 3.8, use \"async def\" instead\n",
      "  def b():\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def a():\n",
    "    print(\"ba\")\n",
    "\n",
    "@asyncio.coroutine #deprecated \n",
    "def b():\n",
    "    print(\"ca\")\n",
    "\n",
    "async def start():\n",
    "    print('a')\n",
    "    await asyncio.gather(a(),b()) #basicamente \"Promise.all\". por algum motivo não é uma lista aqui...\n",
    "    print('xi')\n",
    "    return '!'\n",
    "    \n",
    "print(*await asyncio.gather(start()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. No python, existe um tipo chamado Awaitable que inclui corrotinas e Futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future ----------------------------\n",
      "<class '_asyncio.Future'> <Future pending>\n",
      "True\n",
      "<method-wrapper '__await__' of _asyncio.Future object at 0x7f06b095f840>\n",
      "Function ----------------------------\n",
      "<class 'function'> <function test at 0x7f06b00d7af0>\n",
      "False\n",
      "Coroutine ----------------------------\n",
      "<class 'coroutine'> <coroutine object test at 0x7f06b00ea140>\n",
      "True\n",
      "<method-wrapper '__await__' of coroutine object at 0x7f06b00ea2c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-e1ae3d488fdd>:18: RuntimeWarning: coroutine 'test' was never awaited\n",
      "  print(type(test()), str(test()))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "<ipython-input-9-e1ae3d488fdd>:19: RuntimeWarning: coroutine 'test' was never awaited\n",
      "  print(isinstance(test(), Awaitable))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "<ipython-input-9-e1ae3d488fdd>:20: RuntimeWarning: coroutine 'test' was never awaited\n",
      "  print(test().__await__)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from typing import Awaitable\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "x = loop.create_future()\n",
    "async def test():\n",
    "    return\n",
    "\n",
    "print('Future ----------------------------')\n",
    "print(type(x), str(x))\n",
    "print(isinstance(x, Awaitable))\n",
    "print(x.__await__)\n",
    "\n",
    "print('Function ----------------------------')\n",
    "print(type(test), str(test))\n",
    "print(isinstance(test, Awaitable))\n",
    "\n",
    "print('Coroutine ----------------------------')\n",
    "print(type(test()), str(test()))\n",
    "print(isinstance(test(), Awaitable))\n",
    "print(test().__await__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYEoVT97aJV4"
   },
   "source": [
    "## Act 2: Threading\n",
    "\n",
    "Requirements:  \n",
    "- python >= 2.7  \n",
    "( para python < 3.7, verifique a documentação pq tem umas treta )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MlOTqtegjFI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bar 22\n",
      "ba 22\n",
      "dos 22\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "make_cpu_hot = False\n",
    "size = 300*1000*1000 if make_cpu_hot else 999\n",
    "\n",
    "def f():\n",
    "    out = str(threading.currentThread().getName())\n",
    "    out += ' %d' % (sum(range(0,size)) % 23)\n",
    "    print(out)\n",
    "\n",
    "def main():\n",
    "    t1 = threading.Thread(target=f, name='Bar')          \n",
    "    t2 = threading.Thread(target=f, name='ba')\n",
    "    t3 = threading.Thread(target=f, name='dos')\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t3.start()\n",
    " \n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    t3.join()\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with make_cpu_how == True\n",
    "![ONE CPU BURNING](single-cpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Módulos externos\n",
    "1. Algums módulos como o Numpy implementam suas estruturas de dados e métodos pré compilados em C. Como o interpretador só precisa invocar o módulo e consegue ficar livre para executar outra thread, as mesmas conseguem rodar em paralelo com mais facilidade!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bar 22\n",
      "ba 22\n",
      "dos 22\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "make_cpu_hot = False\n",
    "size = 300*1000*1000 if make_cpu_hot else 999\n",
    "\n",
    "def f():\n",
    "    out = str(threading.currentThread().getName())\n",
    "    out += ' %d' % np.mod(np.sum(np.arange(0,size)),23)\n",
    "    print(out)\n",
    "\n",
    "def main():\n",
    "    t1 = threading.Thread(target=f, name='Bar')          \n",
    "    t2 = threading.Thread(target=f, name='ba')\n",
    "    t3 = threading.Thread(target=f, name='dos')\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t3.start()\n",
    " \n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    t3.join()\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING: A LOT OF RAM**  \n",
    "with make_cpu_how == True\n",
    "![ONE CPU BURNING](multi-cpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicas práticas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16024 squared is 256768576\n",
      "7147 squared is 51079609\n",
      "1361 squared is 1852321\n",
      "9444 squared is 89189136\n",
      "9449 squared is 89283601\n",
      "17280 squared is 298598400\n",
      "9561 squared is 91412721\n",
      "5025 squared is 25250625\n",
      "15835 squared is 250747225\n",
      "6094 squared is 37136836\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "\n",
    "def f(X):\n",
    "    return np.power(X, 2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X = [np.random.randint(20000) for i in range(10)]\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        future_set = {executor.submit(f, x): x\n",
    "                      for x in X}\n",
    "        \n",
    "    for future in as_completed(future_set):\n",
    "        print(future_set[future], 'squared is', future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Act 3: Multiprocessing\n",
    "\n",
    "1. O módulo de multiprocessing resolve o problema do GLI criando um interpretador pra cada processo. Isso gasta mais memória e mais CPU e tem um overhead de inicialização maior. Mas é o método mais recomendado pra tarefas gerais se você não precisa extrair cada gota de performance e só quer paralelizar rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bar 22\n",
      "ba 22\n",
      "dos 22\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, current_process\n",
    "\n",
    "make_cpu_hot = False\n",
    "size = 10*1000*1000*1000 if make_cpu_hot else 999\n",
    "\n",
    "def f():\n",
    "    out = str(current_process().name)\n",
    "    out += ' %d' % (sum(range(0,size)) % 23)\n",
    "    print(out)\n",
    "\n",
    "def main():\n",
    "    t1 = Process(target=f, name='Bar')          \n",
    "    t2 = Process(target=f, name='ba')\n",
    "    t3 = Process(target=f, name='dos')\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t3.start()\n",
    " \n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    t3.join()\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with make_cpu_how == True\n",
    "![ONE CPU BURNING](multi-process.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicas práticas\n",
    "1. Pool simplificado em 3 passos fáceis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250 squared is 39062500\n",
      "6198 squared is 38415204\n",
      "4036 squared is 16289296\n",
      "5930 squared is 35164900\n",
      "19135 squared is 366148225\n",
      "7031 squared is 49434961\n",
      "19447 squared is 378185809\n",
      "13000 squared is 169000000\n",
      "2361 squared is 5574321\n",
      "10680 squared is 114062400\n"
     ]
    }
   ],
   "source": [
    "# 1 importa\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def f(X):\n",
    "    return np.power(X, 2)\n",
    "X = [np.random.randint(20000) for i in range(10)]\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    # 2 instancia\n",
    "    with Pool(processes=cpu_count()) as p:\n",
    "        # 3 map\n",
    "        Y = p.map(f, X)\n",
    "\n",
    "for x,y in list(zip(X, Y)):\n",
    "    print(x, 'squared is', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. concurrent.futures também tem uma interface pra multiprocessing! E os métodos são os mesmos que pra threads!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18289 squared is 334487521\n",
      "16427 squared is 269846329\n",
      "19469 squared is 379041961\n",
      "8560 squared is 73273600\n",
      "10179 squared is 103612041\n",
      "10484 squared is 109914256\n",
      "16816 squared is 282777856\n",
      "8328 squared is 69355584\n",
      "1405 squared is 1974025\n",
      "18631 squared is 347114161\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "\n",
    "def f(X):\n",
    "    return np.power(X, 2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X = [np.random.randint(20000) for i in range(10)]\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        future_set = {executor.submit(f, x): x\n",
    "                      for x in X}\n",
    "        \n",
    "    for future in as_completed(future_set):\n",
    "        print(future_set[future], 'squared is', future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "O foco de python é ser amigável pra escrever e entender, dá pra resolver de todo tipo de problema, mas nem sempre é a melhor ferramenta. Mas na maior parte das vezes é bom o suficiente se você observar esses detalhes.\n",
    "\n",
    "Nesse notebook eu poderia cobrir Dask, Spark e outras ferramentas que também tem implementações de paralelismo, mas não rolou tempo! xP"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MultiPython",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
